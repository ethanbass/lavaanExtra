---
title: "Full CFA/SEM workflow"
author: "Rémi Thériault"
date: "August 29, 2022"
output:
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Full CFA/SEM workflow}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r , include=FALSE}
library(knitr)

pkgs <- c(
  "tibble", "flextable", "lavaanPlot", "DiagrammeRsvg",
  "rsvg", "png", "webshot", "tidySEM", "tmvnsim", "semTools",
  "psych"
)
successfully_loaded <- vapply(pkgs, requireNamespace, FUN.VALUE = logical(1L), quietly = TRUE)
can_evaluate <- all(successfully_loaded)

if (can_evaluate) {
  knitr::opts_chunk$set(eval = TRUE)
  vapply(pkgs, require, FUN.VALUE = logical(1L), quietly = TRUE, character.only = TRUE)
} else {
  knitr::opts_chunk$set(eval = FALSE)
}
```

## CFA example

```{r cfaplot1, message = FALSE}
# Load library
library(lavaan)
library(lavaanExtra)
library(tibble)
library(semTools)
library(psych)

# Define latent variables
x <- paste0("x", 1:9)
latent <- list(
  visual = x[1:3],
  textual = x[4:6],
  speed = x[7:9]
)

# Write the model, and check it
cfa.model <- write_lavaan(latent = latent)
cat(cfa.model)

# Fit the model fit and plot with `lavaanExtra::cfa_fit_plot`
# to get the factor loadings visually (optionally as PDF)
fit.cfa <- cfa_fit_plot(cfa.model, HolzingerSwineford1939)
```

<img src="https://lavaanextra.remi-theriault.com/reference/figures/cfaplot.png" width="30%" />

```{r cfa2}
# Get fit indices
nice_fit(fit.cfa)

# We can get it prettier with the `rempsyc::nice_table` integration
nice_fit(fit.cfa, nice_table = TRUE)
```

But let's say you wanted to develop a short-scale with only x items per dimension. You could decide to remove, for each dimension, the items with the lowest loadings to reach your desired number of items per dimension (but have a look at the #estimation-of-items-reliability section below). You can do so without have to respecify the model, only what items you wish to remove:

```{r cfaplot4}
# Fit the model fit and plot with `lavaanExtra::cfa_fit_plot`
# to get the factor loadings visually (as PDF)
fit.cfa2 <- cfa_fit_plot(cfa.model, HolzingerSwineford1939,
  remove.items = x[c(2, 6:7)]
)
```

<img src="https://lavaanextra.remi-theriault.com/reference/figures/cfaplot2.png" width="30%" />

Let's compare the fit with this short version:

```{r cfaplot5}
fit_table <- nice_fit(lst(fit.cfa, fit.cfa2), nice_table = TRUE)
fit_table
```

If you like this table, you may also wish to save it to Word. Also easy:

```{r cfaplot6}
# Save fit table to Word!
flextable::save_as_docx(fit_table, path = "fit_table.docx")
```

Note that it will also render to PDF in an `rmarkdown` document with `output: pdf_document`, 
but using `latex_engine: xelatex` is necessary when including Unicode symbols
in tables like with the `nice_fit()` function.

```{r, echo=FALSE}
unlink("fit_table.docx")
```

### Estimation of items reliability

Ideally, rather than just looking at the loadings, we would also estimate the item reliability of our dimensions for our long vs short scales to help select which items to drop for our short scale. We can first look at the alpha when an item is dropped using the `psych::alpha` function.

```{r, message=FALSE}
visual <- HolzingerSwineford1939[x[1:3]]
textual <- HolzingerSwineford1939[x[4:6]]
speed <- HolzingerSwineford1939[x[7:9]]

alpha(visual)
alpha(textual)
alpha(speed)

```

Looking at the "Reliability if an item is dropped" section, we can see that our decision to drop items 2, 6, and 7, is consistent with these new results except for item 7. Indeed, according to this reliability estimation, it would be better to drop item 9 instead.

We can also have a look at omega instead, using the `semTools::compRelSEM()` function. First, we look at the omega reliability indice for the three dimensions for each of our models.

```{r}
compRelSEM(fit.cfa)
compRelSEM(fit.cfa2)
```

We can see that the omegas are pretty similar between the two models. Next, let's look at each dimension's omega when a particular item is dropped.

```{r}
mod1 <- write_lavaan(latent = list(visual = x[1:3]))
mod2 <- write_lavaan(latent = list(textual = x[4:6]))
mod3 <- write_lavaan(latent = list(speed = x[7:9]))

fit1 <- cfa(mod1, HolzingerSwineford1939)
fit2 <- cfa(mod2, HolzingerSwineford1939)
fit3 <- cfa(mod3, HolzingerSwineford1939)

data.frame(Drop = x[1:3], Omega = sapply(
  x[1:3], USE.NAMES = FALSE, function(i) compRelSEM(fit1, omit.indicators = i)))
data.frame(Drop = x[4:6], Omega = sapply(
  x[4:6], USE.NAMES = FALSE, function(i) compRelSEM(fit2, omit.indicators = i)))
data.frame(Drop = x[7:9], Omega = sapply(
  x[7:9], USE.NAMES = FALSE, function(i) compRelSEM(fit3, omit.indicators = i)))

```

Looking at the omega values when a specific item is dropped, we can see that, again, our decision to drop items 2, 6, and 7, is consistent with these new results except for item 7, where it would be slightly better to drop item 9 instead (so same conclusion as with alpha).

## SEM example

Here is a structural equation model example. We start with a path analysis first.

### Saturated model

One might decide to look at the saturated `lavaan` model first.

```{r saturated}
# Calculate scale averages
data <- HolzingerSwineford1939
data$visual <- rowMeans(data[x[1:3]])
data$textual <- rowMeans(data[x[4:6]])
data$speed <- rowMeans(data[x[7:9]])

# Define our variables
M <- "visual"
IV <- c("ageyr", "grade")
DV <- c("speed", "textual")

# Define our lavaan lists
mediation <- list(speed = M, textual = M, visual = IV)
regression <- list(speed = IV, textual = IV)
covariance <- list(speed = "textual", ageyr = "grade")

# Write the model, and check it
model.saturated <- write_lavaan(
  mediation = mediation, 
  regression = regression, 
  covariance = covariance)
cat(model.saturated)
```

This looks good so far, but we might also want to check our indirect effects (mediations). For this, we have to obtain the path names by setting `label = TRUE`. This will allow us to define our indirect effects and feed them back to `write_lavaan`.

```{r saturated2}
# We can run the model again.
# However, we set `label = TRUE` to get the path names
model.saturated <- write_lavaan(
  mediation = mediation, 
  regression = regression, 
  covariance = covariance, 
  label = TRUE)
cat(model.saturated)
```

Here, if we check the mediation section of the model, we see that it has been "augmented" with the path names. Those are `visual_speed`, `visual_textual`, `ageyr_visual`, and `grade_visual`. The logic for the determination of the path names is predictable: it is always the predictor variable, on the left, followed by the predicted variable, on the right. So if we were to test all possible indirect effects, we would define our `indirect` object as such:

```{r saturated3}
# Define indirect object
indirect <- list(
  ageyr_visual_speed = c("ageyr_visual", "visual_speed"),
  ageyr_visual_textual = c("ageyr_visual", "visual_textual"),
  grade_visual_speed = c("grade_visual", "visual_speed"),
  grade_visual_textual = c("grade_visual", "visual_textual")
)

# Write the model, and check it
model.saturated <- write_lavaan(
  mediation = mediation, 
  regression = regression, 
  covariance = covariance,
  indirect = indirect,
  label = TRUE
)
cat(model.saturated)
```

If preferred (e.g., when dealing with long variable names), one can choose to use letters for the predictor variables. Note however that this tends to be somewhat more confusing and ambiguous.

```{r letters}
# Write the model, and check it
model.saturated <- write_lavaan(
  mediation = mediation, 
  regression = regression, 
  covariance = covariance,
  label = TRUE, 
  use.letters = TRUE
)
cat(model.saturated)
```

In this case, the path names are `a_speed`, `a_textual`, `a_visual`, and `b_visual`. So we would define our `indirect` object as such:

```{r letters2}
# Define indirect object
indirect <- list(
  ageyr_visual_speed = c("a_visual", "a_speed"),
  ageyr_visual_textual = c("a_visual", "a_textual"),
  grade_visual_speed = c("b_visual", "a_speed"),
  grade_visual_textual = c("b_visual", "a_textual")
)

# Write the model, and check it
model.saturated <- write_lavaan(
  mediation = mediation, 
  regression = regression, 
  covariance = covariance,
  indirect = indirect,
  label = TRUE, 
  use.letters = TRUE
)
cat(model.saturated)
```

There is also an experimental feature that attempts to produce the indirect effects automatically. This feature requires specifying your independent, dependent, and mediator variables as "IV", "M", and "DV", respectively, in the `indirect` object. In our case, we have already defined those earlier, so we can just feed the proper objects.

```{r saturated4}
# Define indirect object
indirect <- list(IV = IV, M = M, DV = DV)

# Write the model, and check it
model.saturated <- write_lavaan(
  mediation = mediation, 
  regression = regression, 
  covariance = covariance,
  indirect = indirect,
  label = TRUE
)
cat(model.saturated)
```

We are now satisfied with our model, so we can finally fit it!

```{r saturated5}
# Fit the model with `lavaan`
fit.saturated <- sem(model.saturated, data = data)

# Get regression parameters only
# And make it pretty with the `rempsyc::nice_table` integration
lavaan_reg(fit.saturated, nice_table = TRUE, highlight = TRUE)
```

So `speed` as predicted by `ageyr` isn't significant. We could remove that path from the model it if we are trying to make a more parsimonious model. Let's make the non-saturated path analysis model next.

### Path analysis model

Because we use `lavaanExtra`, we don't have to redefine the entire model: simply what we want to update. In this case, the regressions and the indirect effects.

```{r path}
regression <- list(speed = "grade", textual = IV)

# We can run the model again, setting `label = TRUE` to get the path names
model.path <- write_lavaan(
  mediation = mediation, 
  regression = regression, 
  covariance = covariance, 
  label = TRUE)
cat(model.path)
# We check that we have removed "ageyr" correctly from "speed" in the
# regression section. OK.

# Define just our indirect effects of interest
indirect <- list(
  age_visual_speed = c("ageyr_visual", "visual_speed"),
  grade_visual_textual = c("grade_visual", "visual_textual")
)

# We run the model again, with the indirect effects
model.path <- write_lavaan(
  mediation = mediation, 
  regression = regression, 
  covariance = covariance,
  indirect = indirect,
  label = TRUE
)
cat(model.path)

# Fit the model with `lavaan`
fit.path <- sem(model.path, data = data)

# Get regression parameters only
lavaan_reg(fit.path)

# We can get it prettier with the `rempsyc::nice_table` integration
lavaan_reg(fit.path, nice_table = TRUE, highlight = TRUE)

# We only kept significant regressions. Good (for this demo).

# Get correlations
lavaan_cor(fit.path)

# We can get it prettier with the `rempsyc::nice_table` integration
lavaan_cor(fit.path, nice_table = TRUE)

# Get nice fit indices with the `rempsyc::nice_table` integration
nice_fit(lst(fit.cfa, fit.saturated, fit.path), nice_table = TRUE)

# Let's get the indirect effects only
lavaan_ind(fit.path)

# We can get it prettier with the `rempsyc::nice_table` integration
lavaan_ind(fit.path, nice_table = TRUE)

# Get modification indices only
modindices(fit.path, sort = TRUE, maximum.number = 5)
```

For reference, this is our model, visually speaking

<img src="https://lavaanextra.remi-theriault.com/reference/figures/holzinger_model.png" />

We could also attempt to draw it with `lavaanExtra::nice_tidySEM`, a convenience wrapper around the amazing `tidySEM` package.

```{r nice_tidySEM, message=FALSE}
labels <- list(
  ageyr = "Age (year)",
  grade = "Grade",
  visual = "Visual",
  speed = "Speed",
  textual = "Textual"
)
layout <- list(IV = IV, M = M, DV = DV)

nice_tidySEM(fit.path,
  layout = layout, label = labels,
  hide_nonsig_edges = TRUE, label_location = .60
)
```


### Latent model

Finally, perhaps we change our mind and decide to run a full SEM instead, with latent variables. Fear not: we don't have to redo everything again. We can simply define our latent variables and proceed. In this example, we have *already* defined our latent variable for our CFA earlier, so we don't even need to write that again!

```{r latent}
model.latent <- write_lavaan(
  mediation = mediation, 
  regression = regression, 
  covariance = covariance,
  indirect = indirect, 
  latent = latent,
  label = TRUE
)
cat(model.latent)

# Run model
fit.latent <- sem(model.latent, data = HolzingerSwineford1939)

# Get nice fit indices with the `rempsyc::nice_table` integration
nice_fit(lst(fit.cfa, fit.saturated, fit.path, fit.latent), nice_table = TRUE)
```
